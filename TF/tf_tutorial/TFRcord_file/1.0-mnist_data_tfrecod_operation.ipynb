{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist data to TFRecord & read tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# load mnist data, if there is no data in dir F:\\dataSets\\mnist, ten\n",
    "# tensorflow will download data\n",
    "mnist = input_data.read_data_sets('F:\\dataSets\\mnist', dtype=tf.uint8, one_hot=True)\n",
    "\n",
    "def Int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def Bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def convert_to_tfrecord_mnist(tfrecord_fname, train_data=True):\n",
    "    if train_data == True:\n",
    "        images = mnist.train.images\n",
    "        labels = mnist.train.labels\n",
    "        num_examples = mnist.train.num_examples\n",
    "    else:\n",
    "        images = mnist.test.images\n",
    "        labels = mnist.test.labels\n",
    "        num_examples = mnist.test.num_examples\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecord_fname)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        img_to_str = images[i].tostring()\n",
    "\n",
    "        feature = {\n",
    "            'image_raw':    Bytes_feature(img_to_str),\n",
    "            'label':        Int64_feature(np.argmax(labels[i]))\n",
    "        }\n",
    "\n",
    "        features = tf.train.Features(feature=feature)\n",
    "        example = tf.train.Example(features=features)\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    print('convert mnist data to tfrecord format done!')\n",
    "\n",
    "def create_tfrecord_mnist():\n",
    "    train_tfrecord_filename = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_train.tfrecord'\n",
    "    val_tfrecord_filename = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_val.tfrecord'\n",
    "\n",
    "    convert_to_tfrecord_mnist(train_tfrecord_filename)\n",
    "    convert_to_tfrecord_mnist(val_tfrecord_filename, False)\n",
    "\n",
    "def read_tfrecord_minst():\n",
    "    fname = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_train.tfrecord'\n",
    "    \n",
    "    # Create a TFRecordReader instance\n",
    "    reader = tf.TFRecordReader()\n",
    "\n",
    "    # Create a queue which maintain file list\n",
    "    filename_queue = tf.train.string_input_producer([fname])\n",
    "\n",
    "    # Read a example data use TFRecordReader instance\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    # Parse readed example data by parse_single_example()\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert stirng format image to array by decode_raw()\n",
    "    images = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    labels = tf.cast(features['labels'], tf.int32)\n",
    "\n",
    "    # Prosess with session\n",
    "    with tf.Session() as sess:\n",
    "        # Run multi-thread\n",
    "        coordinator = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "\n",
    "        for i in range(10):\n",
    "            image, label, pixel = sess.run([images, labels])\n",
    "            print(label)\n",
    "\n",
    "        coordinator.request_stop()\n",
    "        coordinator.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras model with tfrecord iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import FixedLenFeature\n",
    "\n",
    "mnist_feature = {\n",
    "    'image_raw':    tf.FixedLenFeature([], tf.string),\n",
    "    'label':        tf.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def parse_mnist_record(example_proto, clip=False):\n",
    "    ex = tf.parse_single_example(example_proto, mnist_feature)\n",
    "    img = tf.decode_raw(ex['image_raw'], tf.uint8)\n",
    "    img = tf.reshape(img, [28, 28, 1])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    #label = tf.cast(ex['labels'], tf.int32)\n",
    "    label = tf.cast(ex['label'], tf.int32)\n",
    "    label = tf.one_hot(label, 10)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "def creat_mnist_data(tfrecord_file):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_mnist_record, num_parallel_calls=8)\n",
    "    dataset = dataset.repeat().shuffle(1000).batch(32)\n",
    "    iter = dataset.make_one_shot_iterator()\n",
    "\n",
    "    return iter\n",
    "\n",
    "\n",
    "train_tfrecord = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_train.tfrecord'\n",
    "val_tfrecord = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_val.tfrecord'\n",
    "\n",
    "train_iter = creat_mnist_data(train_tfrecord)\n",
    "val_iter = creat_mnist_data(val_tfrecord)\n",
    "\n",
    "model_input = keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same')(model_input)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(32, (3, 3))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(10)(x)\n",
    "model_output = Activation('softmax')(x)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "his = model.fit(train_iter, steps_per_epoch=1562, verbose=1, epochs=5, \n",
    "                validation_data=val_iter, validation_steps=20)\n",
    "\n",
    "\n",
    "loss = his.history['loss']\n",
    "val_loss = his.history['val_loss']\n",
    "plt.plot(loss, linewidth=3, label='train')\n",
    "plt.plot(val_loss, linewidth=3, label='valid')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = his.history['acc']\n",
    "val_acc = his.history['val_acc']\n",
    "plt.plot(acc, linewidth=3, label='train')\n",
    "plt.plot(val_acc, linewidth=3, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras model with tfrecord image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import FixedLenFeature\n",
    "mnist_feature = {\n",
    "    'image_raw':    tf.FixedLenFeature([], tf.string),\n",
    "    'label':        tf.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def parse_mnist_record(example_proto, clip=False):\n",
    "    ex = tf.parse_single_example(example_proto, mnist_feature)\n",
    "    img = tf.decode_raw(ex['image_raw'], tf.uint8)\n",
    "    label = tf.cast(ex['label'], tf.int32)\n",
    "\n",
    "    return img, label\n",
    "\n",
    "def creat_mnist_data(tfrecord_file):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_mnist_record, num_parallel_calls=8)\n",
    "    dataset = dataset.repeat().shuffle(1000).batch(32)\n",
    "    iter = dataset.make_one_shot_iterator()\n",
    "    images, labels = iter.get_next()\n",
    "    images = tf.reshape(images, [-1, 28, 28, 1])\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    labels = tf.one_hot(labels, 10)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "train_tfrecord = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_train.tfrecord'\n",
    "val_tfrecord = 'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\mnist_val.tfrecord'\n",
    "\n",
    "train_images, train_labels = creat_mnist_data(train_tfrecord)\n",
    "val_images, val_labels = creat_mnist_data(val_tfrecord)\n",
    "\n",
    "\n",
    "model_input = keras.layers.Input(tensor=train_images)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same', input_shape=(28, 28, 1))(model_input)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(32, (3, 3))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(10)(x)\n",
    "model_output = Activation('softmax')(x)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',\n",
    "              metrics=['accuracy'], target_tensors=[train_labels],)\n",
    "his = model.fit(steps_per_epoch=1562, verbose=1, epochs=2)\n",
    "\n",
    "\n",
    "loss = his.history['loss']\n",
    "val_loss = his.history['val_loss']\n",
    "plt.plot(loss, linewidth=3, label='train')\n",
    "plt.plot(val_loss, linewidth=3, label='valid')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mnist data serialize to TFRecod file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# load mnist data, if there is no data in dir F:\\dataSets\\mnist, ten\n",
    "# tensorflow will download data\n",
    "mnist = input_data.read_data_sets('F:\\dataSets\\mnist', dtype=tf.uint8, one_hot=True)\n",
    "\n",
    "def Int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def Bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# Read mnist data\n",
    "images = mnist.train.images\n",
    "labels = mnist.train.labels\n",
    "pixels = images.shape[1]\n",
    "num_examples = mnist.train.num_examples\n",
    "\n",
    "# TFRecord data directory.\n",
    "# Alert! 'F:\\dataSets\\TFRecod_data\\mnist', mnist must not exist, tensorflow will\n",
    "# auto create a mnist file\n",
    "filename = 'F:\\dataSets\\TFRecod_data\\mnist'\n",
    "\n",
    "# create a python_io.TFRecordWriter instance\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "for i in range(num_examples):\n",
    "    # convert image into a string\n",
    "    image_to_string = images[i].tostring()\n",
    "\n",
    "    feature = {\n",
    "        'pixels':       Int64_feature(pixels),\n",
    "        'labels':       Int64_feature(np.argmax(labels[i])),\n",
    "        'image_raw':    Bytes_feature(image_to_string)\n",
    "    }\n",
    "\n",
    "    features = tf.train.Features(feature=feature)\n",
    "\n",
    "    # define a Example class, and write inof to it\n",
    "    example = tf.train.Example(features=features)\n",
    "\n",
    "    # write a Example object to TFRecord file\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "c = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TFRecordReader instance\n",
    "reader = tf.TFRecordReader()\n",
    "\n",
    "# Create a queue which maintain file list\n",
    "filename_queue = tf.train.string_input_producer(['F:\\dataSets\\TFRecod_data\\mnist'])\n",
    "\n",
    "# Read a example data use TFRecordReader instance\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# Parse readed example data by parse_single_example()\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "    'image_raw':    tf.FixedLenFeature([], tf.string),\n",
    "    'pixels':       tf.FixedLenFeature([], tf.int64),\n",
    "    'labels':        tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Convert stirng format image to array by decode_raw()\n",
    "images = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "labels = tf.cast(features['labels'], tf.int32)\n",
    "pixels = tf.cast(features['pixels'], tf.int32)\n",
    "\n",
    "# Prosess with session\n",
    "with tf.Session() as sess:\n",
    "    # Run multi-thread\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "\n",
    "    for i in range(10):\n",
    "        image, label, pixel = sess.run([images, labels, pixels])\n",
    "        print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mnist test data into multi TFRecord file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('F:\\dataSets\\mnist', dtype=tf.uint8, one_hot=True)\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "images = mnist.test.images\n",
    "labels = mnist.test.labels\n",
    "pixels = images.shape[1]\n",
    "num_examples = mnist.test.num_examples\n",
    "\n",
    "# Define the number of TFRecord files coorresponding to test data\n",
    "num_files = 2\n",
    "\n",
    "for i in range(num_files):\n",
    "    filename = ('F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\test_data\\\\mnist_test_tfrecod-%.1d-of-%.1d' % (i, num_files))\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_string = images[index].tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'pixels':   _int64_feature(pixels),\n",
    "                'labels':   _int64_feature(np.argmax(labels[index])),\n",
    "                'image_raw':_bytes_feature(image_string)\n",
    "            }\n",
    "        ))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read multi TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "files = tf.train.match_filenames_once(\"F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\test_data\\\\*\")\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False)\n",
    "# filename_queue = tf.train.string_input_producer(['F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\test_data\\\\mnist_test_tfrecod-0-of-2',\n",
    "#                                                  'F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\test_data\\\\mnist_test_tfrecod-1-of-2'])\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'image_raw':    tf.FixedLenFeature([], tf.string),\n",
    "        'pixels':       tf.FixedLenFeature([], tf.int64),\n",
    "        'labels':       tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    ")\n",
    "\n",
    "images = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "labels = tf.cast(features['labels'], tf.int32)\n",
    "pixels = tf.cast(features['pixels'], tf.int32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()  # must add this\n",
    "\n",
    "    print(sess.run(files))\n",
    "\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "\n",
    "    for i in range(6):\n",
    "        print(sess.run([images, labels]))\n",
    "\n",
    "    coordinator.request_stop()\n",
    "    coordinator.join(threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TFRecord files return batch images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "files = tf.train.match_filenames_once(\"F:\\dataSets\\TFRecod_data\\mnist_TFRecord\\\\test_data\\\\*\")\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=True)\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'image_raw':    tf.FixedLenFeature([], tf.string),\n",
    "        'pixels':       tf.FixedLenFeature([], tf.int64),\n",
    "        'labels':       tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    ")\n",
    "\n",
    "images = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "labels = tf.cast(features['labels'], tf.int32)\n",
    "pixels = tf.cast(features['pixels'], tf.int32)\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Set queue's catch capacity that used for generate batch images\n",
    "capacity = 5000 + 3 * batch_size\n",
    "\n",
    "images.set_shape(784) # must set or report error\n",
    "image_batch, label_batch = tf.train.batch([images, labels], batch_size=batch_size, capacity=capacity)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    for i in range(3):\n",
    "        xs, ys = sess.run([image_batch, label_batch])\n",
    "        print(xs, ys)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
