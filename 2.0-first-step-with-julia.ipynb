{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\keras-gpu\\lib\\site-packages\\scipy\\misc\\pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n  if issubdtype(ts, int):\nD:\\anaconda\\envs\\keras-gpu\\lib\\site-packages\\scipy\\misc\\pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin img data shape:  (6283, 32, 32)\nnew img data shape:  (6283, 32, 32, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin img data shape:  (6220, 32, 32)\nnew img data shape:  (6220, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from natsort import natsorted\n",
    "\n",
    "path = 'E:/dataSets/chars74K/data'\n",
    "\n",
    "# preprocessed image size\n",
    "img_height, img_width = 32, 32\n",
    "\n",
    "# preprocessed image dir\n",
    "suffix = 'Preproc'\n",
    "train_data_path = path + '/train' + suffix\n",
    "test_data_path = path + '/test' + suffix\n",
    "\n",
    "# create dir\n",
    "if not os.path.exists(train_data_path):\n",
    "    os.makedirs(train_data_path)\n",
    "\n",
    "if not os.path.exists(test_data_path):\n",
    "    os.makedirs(test_data_path)\n",
    "    \n",
    "# process image's size and color\n",
    "for datasetType in ['train', 'test']:\n",
    "    imgFiles = natsorted(glob.glob(path + '/' + datasetType + '/*'))\n",
    "    imgData = np.zeros((len(imgFiles), img_height, img_width))\n",
    "    \n",
    "    for i, imgFilePath in enumerate(imgFiles):\n",
    "        # Color image\n",
    "        img = imread(imgFilePath, True)\n",
    "        \n",
    "        imgResized = imresize(img, (img_height, img_width))\n",
    "        imgData[i] = imgResized\n",
    "        \n",
    "        # store processed image\n",
    "        filename = os.path.basename(imgFilePath)\n",
    "        filenameDotSplit = filename.split('.')\n",
    "        newFilename = str(int(filenameDotSplit[0])).zfill(5) + \".\" + str(filenameDotSplit[-1].lower())\n",
    "        newFilePath = path + '/' + datasetType + suffix + \"/\" + newFilename\n",
    "        imsave(newFilePath, imgResized)\n",
    "        \n",
    "    print('origin img data shape: ', imgData.shape)\n",
    "    imgData = imgData[:, :, :, np.newaxis]\n",
    "    print('new img data shape: ', imgData.shape)\n",
    "        \n",
    "    imgData = imgData.astype('float32') / 255.\n",
    "    np.save(path + '/' + datasetType + suffix + '.npy', imgData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "def label2int(ch):\n",
    "    #process into 0 - 61\n",
    "    asciiVal = ord(ch)\n",
    "    if (asciiVal <= 57): # 0-9\n",
    "        asciiVal -= 48\n",
    "    elif (asciiVal <= 90): #A -Z\n",
    "        asciiVal -= 55\n",
    "    else: # a-z\n",
    "        asciiVal -= 61\n",
    "    return asciiVal\n",
    "\n",
    "def int2label(i):\n",
    "    if (i <= 9):\n",
    "        i += 48\n",
    "    elif (i <= 35):\n",
    "        i += 55\n",
    "    else:\n",
    "        i += 61\n",
    "    return chr(i)\n",
    "\n",
    "path = 'E:/dataSets/chars74K/data'\n",
    "\n",
    "# read label\n",
    "y_train = pd.read_csv(path + '/trainLabels.csv').values[:, 1]\n",
    "\n",
    "# Encode label\n",
    "Y_train = np.zeros((y_train.shape[0], 62))\n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1 # One-hot\n",
    "    \n",
    "np.save(path + '/' + 'labelsPreproc.npy', Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 32, 32, 128)       1280      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 16, 16, 256)       295168    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 8, 8, 512)         1180160   \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 4096)              33558528  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 62)                254014    \n=================================================================\nTotal params: 57,527,742\nTrainable params: 57,527,742\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 62\n",
    "nb_epoch = 10\n",
    "img_height, img_width = 32, 32\n",
    "path = 'E:/dataSets/chars74K/data'\n",
    "\n",
    "# Load preprocessed data and label\n",
    "X_train_all = np.load(path + '/trainPreproc.npy')\n",
    "Y_train_all = np.load(path + '/labelsPreproc.npy')\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_all, Y_train_all,\n",
    "    test_size=0.25, stratify=np.argmax(Y_train_all, axis=1))\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.3,\n",
    "    channel_shift_range=0.1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(128, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu', input_shape=(img_height, img_width, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu'))\n",
    "model.add(Convolution2D(256, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(512, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu'))\n",
    "model.add(Convolution2D(512, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu'))\n",
    "model.add(Convolution2D(512, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                        activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4712 samples, validate on 1571 samples\nEpoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          validation_data=(X_val, Y_val), verbose=1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adamax',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "saveBestModel = ModelCheckpoint('best.kerasModelWeights',\n",
    "                                monitor='val_acc',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                              steps_per_epoch=len(X_train) // batch_size,\n",
    "                              epochs=nb_epoch,\n",
    "                              validation_data=(X_val, Y_val),\n",
    "                              callbacks=[saveBestModel],\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best.kerasModelWeights')\n",
    "\n",
    "X_test = np.load(path + 'testPreproc.npy')\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "vInt2Label = np.vectorize(int2label)\n",
    "Y_test_pred = vInt2Label(Y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "N = range(len(acc))\n",
    "plt.plot(N, acc, 'bo', label='Training acc')\n",
    "plt.plot(N, val_acc, 'b', label='Validatoin acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(N, loss, 'bo', label='Training loss')\n",
    "plt.plot(N, val_loss, 'b', label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
